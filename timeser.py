###############################################################################
# Chris Rumble
# 1/5/22
#
# A suite of functions for processing time series data from MD simulations.
###############################################################################
import numpy as np
import numba
from dataclasses import dataclass
from tqdm import tqdm
import warnings

######################################
# calcuate probability distributions #
######################################
def calc_pdist(data, endpoints, nbins):
    edges = np.linspace(endpoints[0], endpoints[1], nbins+1)
    bins  = (edges[:-1] + edges[1:])/2
    n     = np.size(np.shape(data))
    if n > 1:
        dist  = np.zeros([nbins, n])
        for i in range(n):
            dist[:,i] = np.histogram(data[:,i], bins=edges, density=True)[0]
    elif n == 1:
        dist = np.histogram(data, bins=edges, density=True)[0]
    else:
        print('I don''t know how to handle these data.')
    return bins, dist

###########################################################################
# calculate a dipole and its moment from a set of coordinates and charges #
###########################################################################
def calc_dipole(coord, q):
    dipole = np.dot(np.squeeze(q), coord)
    return dipole

#############################################################################
# calculate an EFG on atom a generated by atom b in SI base units using JIT #
#############################################################################
@numba.jit()
def pair_efg_jit(a_coord, b_coords, q_b, efg, out):
    n   = len(b_coords[:,0])
    r   = b_coords - a_coord
    
    # efg = np.zeroes(np.asarray([3,3], dtype=np.float64), dtype=np.float64)
    # out = np.zeroes([3,3], dtype=np.float64)

    for i in range(n):
        r0_sq = r[i,0]**2
        r1_sq = r[i,1]**2
        r2_sq = r[i,2]**2

        const = (r0_sq + r1_sq + r2_sq)**(5/2)
        const = const*4*np.pi*8.8541878128e-12
        const = -q_b[i]/const

        # row 1
        efg[0,0] = -2*r0_sq + r1_sq + r2_sq
        efg[0,1] = -3*r[i,0]*r[i,1]
        efg[0,2] = -3*r[i,0]*r[i,2]

        # row 2
        efg[1,0] = efg[0,1]
        efg[1,1] = r0_sq - 2*r1_sq + r2_sq
        efg[1,2] = -3*r[i,1]*r[i,2]

        # row 3
        efg[2,0] = efg[0,2]
        efg[2,1] = efg[1,2]
        efg[2,2] = r0_sq + r1_sq - 2*r2_sq

        out = out + efg*const

    return out 


###################################################################
# calculate an EFG on atom a generated by atom b in SI base units #
###################################################################
def pair_efg(a_coord, b_coord, q_b):
    efg   = np.zeros([3,3])
    r     = b_coord - a_coord
    r0_sq = r[0]**2
    r1_sq = r[1]**2
    r2_sq = r[2]**2

    const = (r0_sq + r1_sq + r2_sq)**(5/2)
    const = const*4*np.pi*8.8541878128e-12
    const = -q_b/const

    # row 1
    efg[0,0] = -2*r0_sq + r1_sq + r2_sq
    efg[0,1] = -3*r[0]*r[1]
    efg[0,2] = -3*r[0]*r[2]

    # row 2
    efg[1,0] = efg[0,1]
    efg[1,1] =    r0_sq - 2*r1_sq + r2_sq
    efg[1,2] = -3*r[1]*r[2]

    # row 3
    efg[2,0] = efg[0,2]
    efg[2,1] = efg[1,2]
    efg[2,2] =    r0_sq + r1_sq - 2*r2_sq

    efg = efg*const

    return efg

######################################################
# read/write a time-dependent tesor file (a la EFGs) #
######################################################
def read_tensor(filename):
    # note that this is for Yann's data format
    raw = np.loadtxt(filename, skiprows=0)
    t   = raw[:,0]
    t   = t[range(0, len(t), 3)]/100
    V   = np.zeros([len(t), 9])
    for i in range(len(t)):
        V[i,:] = np.reshape(raw[3*i:3*i+3, 1:], 9)

    return V, t

def read_tensor_unique(filename):
    # note that this is for Yann's data format
    raw = np.loadtxt(filename, skiprows=0)
    t   = raw[:,0]
    t   = t[range(0, len(t), 3)]/100
    V   = np.zeros([len(t), 9])
    for i in range(len(t)):
        V[i,:] = np.reshape(raw[3*i:3*i+3, 1:], 9)

    V = V[:,[0,1,2,4,5,8]]
    return V, t

def write_tensor(filename, efg):
    f = open(filename, 'w')
    # n_frames = len(efg[:,0,0])/3
    n_frames = len(efg[:,0,0])

    for i in range(n_frames):
        for j in range(3):
            f.write('%15d\t%15E\t%15E\t%15E\n' % (i, 
                                                  efg[i,0,j],
                                                  efg[i,1,j],
                                                  efg[i,2,j]))
    f.close()
    return

###############################################################################
# calculate the tetrahedral structure parameter, DOI: 10.1080/002689798169195 #
###############################################################################
def tetra_par(ligands):
    Sg = 0
    r = np.zeros(4)
    Sk = 0

    r      = np.linalg.norm(ligands, axis=1)
    r_mean = r.mean()
    for i in range(4):
        ligands[i,:] = ligands[i,:]/r[i]
        
    
    for i in range(4):
        Sk = Sk + (r[i] - r_mean)**2/(4*r_mean**2)
        
    Sk = (1/3)*Sk
    
    
    Sg = Sg + (np.dot(ligands[0,:], ligands[1,:]) + 1/3)**2
    Sg = Sg + (np.dot(ligands[0,:], ligands[2,:]) + 1/3)**2
    Sg = Sg + (np.dot(ligands[0,:], ligands[3,:]) + 1/3)**2
    
    Sg = Sg + (np.dot(ligands[1,:], ligands[2,:]) + 1/3)**2
    Sg = Sg + (np.dot(ligands[1,:], ligands[3,:]) + 1/3)**2
    
    Sg = Sg + (np.dot(ligands[2,:], ligands[3,:]) + 1/3)**2

    Sg = 3/32*Sg

    
    
    return np.asarray([Sg, Sk])

###################################################################
# calcuate a mean squared displacement                            #
# don't use this unless you have to, tidynamics is so much faster #
###################################################################
def calc_msd(r, t0_step):
   # r must be a nt x 3 array
    n   = len(r[:,0])
    msd = np.zeros(n)
    ct  = np.zeros(n)
    print('Calculating msd...')
    for i in tqdm(range(0, n, t0_step)):
        msd[:(n-i)] = (msd[:(n-i)] + 
                       np.sum(np.power(r[i:,:] - r[i,:], 2), axis=1))
        ct[:(n-i)]  = ct[:(n-i)] + 1
    msd = msd/ct
    
    return msd


###############################################################################
# Calculates an auto- or crosscorrelation function. No shortcuts are made and #
# all data and t0 are considered                                              #
# don't use this unless you have to, tidynamics is so much faster             # 
###############################################################################
def calc_corr(t, data, stride, ncorr, method='auto', norm=False):
    # check for auto vs. cross correlation
    if   method == 'auto':
        if np.ndim(data) != 1:
            raise Exception('Data array must be one-dimensional ' +
                            'for autocorrelation.')
        data = np.vstack([data, data]).T
    elif method == 'cross':
        if np.ndim(data) != 2:
            raise Exception('Data array must be n x 2 ' +
                            'for cross-correlation.')
            dum = np.shape(data)
            if dum[0] < dum[1]:
                raise Exception('Data array must be n x 2 ' +
                                'for cross-correlation.')
    
    # do the correlation function calculation
    nt     = len(t)
    corr   = np.zeros(ncorr)
    count  = np.zeros(ncorr)
    t_corr = t[0:ncorr]

    pbar = tqdm(total=int(nt/stride))
    for i in range(0, nt, stride):
        chunk = data[i,0]*data[i:i+ncorr,1]
        corr[0:len(chunk)]  = corr[0:len(chunk)] + chunk
        count[0:len(chunk)] = count[0:len(chunk)] + 1
        pbar.update(1)
    pbar.close()
    corr = corr/count
    
    if norm == True:
        corr = corr/corr[0]
    
    return corr, t_corr

@numba.jit(parallel=True)
def calc_corr_jit(t, data, stride, ncorr, norm=True):
    # do the correlation function calculation
    nt     = len(t)
    corr   = np.zeros(ncorr)
    count  = np.zeros(ncorr)
    t_corr = t[0:ncorr]

    for i in range(0, nt, stride):
        chunk = data[i]*data[i:i+ncorr]
        corr[0:len(chunk)]  = corr[0:len(chunk)] + chunk
        count[0:len(chunk)] = count[0:len(chunk)] + 1
    corr = corr/count
    
    if norm == True:
        corr = corr/corr[0]
    
    return corr, t_corr

@numba.jit(parallel=True)
def calc_rtcf_jit(t, orient, stride, ncorr):
    # do the correlation function calculation
    nt     = len(t)
    corr   = np.zeros(ncorr)
    count  = np.zeros(ncorr)
    t_corr = t[0:ncorr]

    for i in range(0, nt, stride):
        chunk = orient[i:i+ncorr, :]
        dum = chunk[0,0]*chunk[:,0]
        dum = chunk[0,1]*chunk[:,1] + dum
        dum = chunk[0,2]*chunk[:,2] + dum
        corr[0:len(chunk)] = corr[0:len(chunk)] + 1.5*dum*dum - 0.5
        
        count[0:len(chunk)] = count[0:len(chunk)] + 1
    corr = corr/count    
    
    return corr, t_corr

###################################################
# resamples a function in linear time to log time #
###################################################
def log_resamp(t, data, n_log):

    # prepare data
    if np.size(np.shape(data)) == 1:
        n_data = 1
        data = np.reshape(data, [len(data), 1])
    elif np.size(np.shape(data)) == 2:
        n_data = np.shape(data)[1]
        
    t_log  = np.logspace(np.log10(t[1]), np.log10(t[-1]), n_log-1)
    t_log  = np.hstack([0, t_log])
    resamp = np.zeros([n_log, n_data])
    
    # do the interpolation
    for i in range(n_data):
        resamp[:,i] = np.interp(x=t_log, xp=t, fp=data[:,i])
        
    if np.shape(data)[1] == 1:
        resamp = np.reshape(resamp, len(resamp))
        
    return t_log, resamp

########################################################################
# caclulates the non-gaussian parameter of a set of values, defined in #
# DOI: 10.1063/1.2371111. Data must be a vector.                       #
########################################################################
def calc_ngp(data):
    from scipy.stats import moment

    ngp = moment(data, moment=4)/moment(data, moment=2)**2
    ngp = ngp/5 - 3/5
    
    
    return ngp

















